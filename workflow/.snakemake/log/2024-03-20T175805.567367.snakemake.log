Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job stats:
job          count
---------  -------
all              1
run_greml        1
total            2

Select jobs to execute...

[Wed Mar 20 17:58:08 2024]
rule run_greml:
    input: /home/lesi11/results/test.grm.bin, /home/lesi11/testData/test.phen
    output: /home/lesi11/results/test.hsq
    jobid: 1
    reason: Missing output files: /home/lesi11/results/test.hsq
    wildcards: name=test
    threads: 4
    resources: tmpdir=/tmp

[Wed Mar 20 17:58:08 2024]
Error in rule run_greml:
    jobid: 1
    input: /home/lesi11/results/test.grm.bin, /home/lesi11/testData/test.phen
    output: /home/lesi11/results/test.hsq
    shell:
        
    gcta64 --grm /home/lesi11/results/test.grm.bin --pheno /home/lesi11/testData/test.phen --reml --out /home/lesi11/results/test --thread-num 4
    
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-03-20T175805.567367.snakemake.log
