Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job stats:
job           count
----------  -------
all               1
grm_to_csv        1
total             2

Select jobs to execute...

[Wed Mar 20 18:23:17 2024]
rule grm_to_csv:
    input: /home/lesi11/testData/test.grm.bin
    output: /home/lesi11/testData/test_size=100.grm.csv
    jobid: 3
    reason: Missing output files: /home/lesi11/testData/test_size=100.grm.csv
    wildcards: name=test, size=100
    resources: tmpdir=/tmp

[Wed Mar 20 18:23:17 2024]
Error in rule grm_to_csv:
    jobid: 3
    input: /home/lesi11/testData/test.grm.bin
    output: /home/lesi11/testData/test_size=100.grm.csv

RuleException:
ValueError in file /sc-projects/sc-proj-dh-ag-eils-ml/workflow/rules/grm.smk, line 24:
Unsupported script: Expecting either Python (.py), R (.R), RMarkdown (.Rmd) or Julia (.jl) script.
  File "/sc-projects/sc-proj-dh-ag-eils-ml/workflow/rules/grm.smk", line 24, in __rule_grm_to_csv
  File "/home/lesi11/.conda/envs/greml/lib/python3.9/concurrent/futures/thread.py", line 58, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-03-20T182314.848009.snakemake.log
